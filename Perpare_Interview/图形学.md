<h2>渲染管线</h2>

5个坐标系

+ 模型坐标系
+ 世界坐标系（通过model矩阵变换得到）
+ 观察者坐标系（通过view矩阵变换得到）
+ 裁剪空间（通过project矩阵变换得到，三维->二维）
+ 屏幕空间

这些变换都发生在顶点着色器中，经过顶点着色器，所有顶点都变成屏幕二维坐标

3个变换矩阵

+  model矩阵：控制了物体的平移，旋转与缩放。3D建模软件中为模型坐标，导入游戏后使用model matrix进行大小、位置、角度的设置
+  View矩阵。将世界坐标系变换到观察者坐标系，通过一些列平移、旋转的组合来移动整个场景，用来模拟一个camera**（并不是移动摄像机，摄像机是一个虚拟概念，事实上代码中并没有摄像机camera，而是用view matrix来表示摄像机，然后把view matrix附加到每一个物体，来模拟摄像机）**
+ projection矩阵。将观察者坐标系转换到裁剪坐标系。将3D坐标投影到2D屏幕上，裁剪空间外的顶点会被裁剪掉，投影矩阵指定了坐标的范围。

<hr>

渲染管线流程：

顶点数据通过**顶点着色器**，经过`gl_Position`变量之后进行归一化，通过`glViewPort()`视口变换进行图元装配（`glDrawArray`或者`glDrawElement`），然后将图元通过**几何着色器**得到更多图元，进行光栅化，插值后的片段进入**片段着色器**进行着色（片段处理程序的input是顶点处理程序的output经过了插值以后得到的值），对着色后的片段进行测试与混合得到最后的像素

![image](https://github.com/yu-cao/Graph-and-Game-Engine/blob/master/Perpare_Interview/pic/render_pipeline.png)

在OpenGL中，`gl_Position`在顶点着色器输出后，会由OpenGL自己进行归一化与视口变换

![image](https://github.com/yu-cao/Graph-and-Game-Engine/blob/master/Perpare_Interview/pic/OpenGL_render_1.png)

3种着色器

  + 顶点着色器：计算顶点的位置，并且把顶点投影到二维屏幕上
  + 几何着色器：将形状（图元）划分为更多的形状（图元），影响后续插值结果
  + 片段着色器：根据根据顶点着色器和几何着色器的输出插值，计算每一个片元的颜色

光栅化

把几何图元（点、线，面）投影到成像平面并确定哪些像素或采样点被图元覆盖。比如给一个三角形的三个顶点，输出绘制这个三角形会覆盖屏幕上哪些像素点

<hr>

OpenGL的缓冲

  + 帧缓冲：用于创建临时的渲染上下文，帧缓冲是一些二维数组和OpenG所使用的存储区的集合：
    + 颜色缓存：包含每个像素的颜色信息（RGBA/颜色索引等等）
    + 深度缓存：包含每个像素的深度值（Z-Buffer）
    + 模板缓存：包含物体的模板值，模板值具有屏蔽作用，用于控制绘制的区域，使得某些区域可画，某些区域不可画
    + 累计缓存：包含颜色信息。其可以合成一系列的绘制结果，实现某些特殊效果
  + 顶点缓冲(Vertex Buffer)：缓存顶点数据
  + 元素缓冲(Element Buffer)：缓存顶点序号数据

<hr>

Alpha混合

通用公式为：`Color = Src * Srcfactor + Dst * Dstfactor`；其中，Src是源颜色向量也就是纹理本来的颜色，Dst是目标颜色向量也就是储存在颜色缓冲中当前位置的颜色向量（先进入颜色缓冲区的是目标颜色，比如在红色方块上绘制绿色方块，则红色是Dst，绿色是Src）

最常用的混合方式是`glBlendFunc(GL_SRC_ALPHA,  GL_ONE_MINUS_SRC_ALPHA);`

<hr>

颜色向量计算

数乘：`n * color`，n越大，结果越亮<br>
点乘：`colorA * colorB`，越大越亮

<hr>

glsl着色器程序创建

![image](https://github.com/yu-cao/Graph-and-Game-Engine/blob/master/Perpare_Interview/pic/Shader.png)

glsl的3种数据传递：

+  uniform变量：外部application程序传递给（vertex和fragment）shader的变量，uniform变量就像是C/C++里面的只读（const），它不能被shader程序修改
+  attribute变量：只能在vertex shader中使用的变量。一般用attribute变量来表示一些顶点的数据，如：顶点坐标，法线，纹理坐标，顶点颜色等。在application中，一般用函数`glBindAttribLocation()`来绑定每个attribute变量的位置，然后用函数`glVertexAttribPointer()`为每个attribute变量赋值
+  varying(in/out)变量，varying变量是vertex和fragment shader之间做数据传递用的。一般vertex shader修改varying变量的值，然后fragment shader使用该varying变量的值。因此varying变量在vertex和fragment shader二者之间的声明必须是一致的。application不能使用此变量。

<hr>

冯氏光照

+  环境光(Ambient Lighting)：即使在黑暗的情况下，世界上通常也仍然有一些光亮（月亮、远处的光），所以物体几乎永远不会是完全黑暗的。为了模拟这个，我们会使用一个环境光照常量，它永远会给物体一些颜色
+  漫反射(Diffuse Lighting)：模拟光源对物体的方向性影响(Directional Impact)。它是冯氏光照模型中视觉上最显著的分量。物体的某一部分越是正对着光源，它就会越亮
+  镜面反射(Specular Lighting)：模拟有光泽物体上面出现的亮点。镜面光照的颜色相比于物体的颜色会更倾向于光的颜色

<hr>

旋转的3种方法

+ 旋转矩阵

优点：旋转轴可以任意；<br>
缺点：旋转只需要知道一个轴+一个角度共4个值，却需要16个元素才能构建旋转矩阵，时间空间上都有浪费

+ 欧拉角(yaw pitch roll)

优点：形象直观，而且只使用了x,y,z三个轴上旋转角度变量，也就是3个3x3矩阵进行变换<br>
缺点：旋转顺序很重要，不同的顺序得到的结果会不同；而且会产生万向节锁

+ 四元数

优点：可以避免万向节锁现象；只需要一个4维的四元数就可以执行绕任意过原点的向量的旋转，方便快捷，在某些实现下比旋转矩阵效率更高；可以提供平滑插值<br>
缺点：欧拉旋转复杂了一点点，因为多了一个维度；理解更困难，不直观

四元数概念与作用

它的虚部包含了三个虚数单位，i、j、k，即一个四元数可以表示为x = a + bi + cj + dk。设一个四元数q = ((x, y, z)，w) = (v, w)，其中v是向量，w是实数，这样的式子来表示一个四元数。

如果我们想要把空间的一个点P绕着单位向量轴u = (x, y, z)表示的旋转轴旋转θ角度，我们首先把点P扩展到四元数空间，即四元数p = (P, 0)。那么，旋转后新的点对应的四元数（当然这个计算而得的四元数的实部为0，虚部系数就是新的坐标）为：`p′=qpq^-1`，其中`q=(cosθ/2, (x,y,z)sinθ/2)`，`q^-1 = q^* / N(q)`，其中q是单位向量，所以四元数模N(q) = 1，q^* 是共轭四元数(-v,w)，乘法是`q1q2=(v1 × v2 + w1v2 + w2v1, w1w2 − v1 ⋅ v2 )`

<hr>

万向节锁

参考[这个解释视频](https://v.youku.com/v_show/id_XNzkyOTIyMTI=.html)

欧拉角旋转要分层级，假设旋转顺序是yxz（规定y只能水平转，x是在y的基础上竖直转（改变俯仰角），z改变相机左倾or右倾）

那么y层级最高，z层级最低，先y旋转的时候会带着x，z和相机一起转，然后x旋转的时候只会带着z和相机一起转，而z旋转的时候只会带着相机一起转；**这个锁发生在y层级与z层级重合的情况（最高层级与最低层级重合），旋转y对于最后的相机而言跟旋转最低层级的z效果一致**（也就是说这时我们丢失了一个旋转轴）

举例如下图：让相机垂直向上，平行屏幕的时候，无法通过yzx的顺序方式把它改成水平，朝向向外，而需要同时改变yzx三个才可以（或者是要按照xzy的方式进行旋转）(想让它转到虚箭头的状态按照现在的层级是不可行的）

![image](https://github.com/yu-cao/Graph-and-Game-Engine/blob/master/Perpare_Interview/pic/Gimbal_Lock.png)

但是如果按照xzy的方式进行旋转改出等于重新规定了一个旋转层级，这样实际上是于事无补的

<hr>

多级渐进纹理Mipmap优缺点

为了加快渲染速度和减少图像锯齿，贴图被处理成由一系列被预先计算和优化过的图片组成的文件,这样的贴图被称为Mipmap(多级渐进纹理)，由一组分辨率逐渐降低的纹理序列组成，每一级纹理宽度和高度都是上一级纹理宽度和高度的一半。宽和高不一定相等，也就是说，这些纹理不一定都是正方形。

优点：提高渲染速度，减少图像锯齿<br>
缺点：会增加额外的内存消耗

<hr>

片段与像素的区别（核心就是：有没有经过test和blend）

+ 片段是渲染一个像素需要的全部信息，所有片段经过测试与混合后渲染成像素。
+ 片段是三维顶点光栅化后的数据集合，还没有经过深度测试，而像素是片段经过深度测试、模板测试、alpha混合之后的结果
+ 片段的个数远远多于像素，因为有的片段会在测试和混合阶段被丢弃，无法被渲染成像素。

<hr>

Z-Buffer算法

+ 需要一个空间保存每个像素的深度，绘制前初始化所有深度为无限远，绘制时当前片段如果比z-buffer中的值大（说明更远），则跳过此片段，保留原来的渲染结果；否则，绘制此片段，并更新z-buffer。
+ 可以处理对透明物体的消除
+ 算法可以并行
+ 与画家算法（首先将场景中的多边形根据深度进行排序，然后按照顺序进行描绘。这种方法通常会将不可见的部分覆盖，这样就可以解决可见性问题）不同，不需要对物体排序

Z-消隐

根据深度信息对像素的早期剔除，当渲染隐藏表面所需要的计算量很大的时候，这种方法可以提升处理性能。